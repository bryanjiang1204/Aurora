{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanjiang1204/aurora/blob/main/AURORA_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aurora Embeddings"
      ],
      "metadata": {
        "id": "1DCbKHyyTKGr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiNMQnJenzZf"
      },
      "source": [
        "## Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fMx70gXn1gY"
      },
      "outputs": [],
      "source": [
        "!pip install fvcore\n",
        "!pip install av\n",
        "!pip install pytorchvideo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpv7IcHTodn8"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzTVlOatrTkN",
        "outputId": "8988fd92-dd10-46a9-8d48-d5ebe85f41b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/X3D_S.pyth\" to /root/.cache/torch/hub/checkpoints/X3D_S.pyth\n",
            "100%|██████████| 29.4M/29.4M [00:00<00:00, 136MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_name = 'x3d_s'\n",
        "model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jGcJmS0o6ik",
        "outputId": "419a2f67-fe13-429b-e617-68a7619d8c12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import CenterCropVideo, NormalizeVideo\n",
        "from pytorchvideo.transforms import ApplyTransformToKey,ShortSideScale, UniformTemporalSubsample\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.25, 0.25, 0.25]\n",
        "\n",
        "num_frames = 13\n",
        "sampling_rate = 6\n",
        "frames_per_second = 30\n",
        "\n",
        "transform =  ApplyTransformToKey(\n",
        "    key=\"video\",\n",
        "    transform=Compose(\n",
        "        [\n",
        "            UniformTemporalSubsample(num_frames),\n",
        "            Lambda(lambda x: x/255.0),\n",
        "            NormalizeVideo(mean, std),\n",
        "            ShortSideScale(size=182),\n",
        "            CenterCropVideo(\n",
        "                crop_size=(182, 182)\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "clip_duration = (num_frames * sampling_rate)/frames_per_second\n",
        "\n",
        "url_link = \"https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\"\n",
        "video_path = 'archery.mp4'\n",
        "try: urllib.URLopener().retrieve(url_link, video_path)\n",
        "except: urllib.request.urlretrieve(url_link, video_path)\n",
        "\n",
        "video = EncodedVideo.from_path(video_path)\n",
        "\n",
        "video_data = video.get_clip(start_sec=0, end_sec=3)\n",
        "video_data = transform(video_data)\n",
        "\n",
        "inputs = video_data[\"video\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwQuKy_oeeX",
        "outputId": "1e5ad6bf-b787-4d95-b6d7-786723fd832b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([8192])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "class Video_Embeddings(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True).eval()\n",
        "        self.body = create_feature_extractor(model, return_nodes={'blocks.5.pool.post_conv': 'embeddings',})\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.body(x)\n",
        "        return x\n",
        "\n",
        "extractor = Video_Embeddings()\n",
        "flat_layer = extractor(inputs[None,...])\n",
        "\n",
        "y = torch.flatten(flat_layer['embeddings'])\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuWx0IxbZMHU"
      },
      "source": [
        "Sanity check, cosine simialrity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yed6FgyXpWiC"
      },
      "source": [
        "## Text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Bert Embeddings"
      ],
      "metadata": {
        "id": "oBA_AvSZcDrI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEASR-p0pYNH"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf-gnsZIpamn"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-B0qnMcpcah"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "input_text = \"Wise Gurus chant\"\n",
        "\n",
        "input_ids = torch.tensor([tokenizer.encode(input_text)])\n",
        "with torch.no_grad():\n",
        "    model_output = model(input_ids)\n",
        "bert_embeddings = model_output[0]\n",
        "\n",
        "x = torch.flatten(bert_embeddings)\n",
        "x.shape\n",
        "#padding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training BERT Classifier"
      ],
      "metadata": {
        "id": "sHh4_VWScFYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def load_imdb_data(data_file):\n",
        "    df = pd.read_csv(data_file,nrows=14000)\n",
        "    #error reached at 14,153!\n",
        "    texts = df['review'].tolist()\n",
        "    labels = [1 if sentiment == \"positive\" else 0 for sentiment in df['sentiment'].tolist()]\n",
        "    return texts, labels\n",
        "\n",
        "data_file = \"/content/drive/My Drive/Archive/IMDB_Dataset.csv\"\n",
        "texts, labels = load_imdb_data(data_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHgM1WttcHLc",
        "outputId": "49cf8978-3cb0-41f7-da6a-ca20f1d7579d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_length):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "  def __getitem__(self, idx):\n",
        "    text = self.texts[idx]\n",
        "    label = self.labels[idx]\n",
        "    encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "    return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
      ],
      "metadata": {
        "id": "jGu_WPa5cLSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self, bert_model_name, num_classes):\n",
        "      super(BERTClassifier, self).__init__()\n",
        "      self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "      outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      pooled_output = outputs.pooler_output\n",
        "      x = self.dropout(pooled_output)\n",
        "      logits = self.fc(x)\n",
        "      return logits"
      ],
      "metadata": {
        "id": "sirbz1hVftTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    for i,batch in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if i == 10:\n",
        "          return"
      ],
      "metadata": {
        "id": "i83mdpLcfycA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: What is a schedular, what is an input_id and attention_mask"
      ],
      "metadata": {
        "id": "GjZKI4znhvDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
      ],
      "metadata": {
        "id": "XF7F1fORf2R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "    return \"positive\" if preds.item() == 1 else \"negative\""
      ],
      "metadata": {
        "id": "OICVKprdf5Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = 2\n",
        "max_length = 128\n",
        "batch_size = 1028\n",
        "num_epochs = 1\n",
        "learning_rate = 2e-5"
      ],
      "metadata": {
        "id": "9h_2nzNvgMDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "clwHot7PgPDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "avQHJFCngRes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BERTClassifier(bert_model_name, num_classes).to(device)"
      ],
      "metadata": {
        "id": "wSXdccWWgVO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_UXr1UXgb2O",
        "outputId": "ccd0e17a-3c0d-477a-96ad-b853e6ce394c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "  train(model, train_dataloader, optimizer, scheduler, device)\n",
        "  accuracy, report = evaluate(model, val_dataloader, device)\n",
        "  print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "  print(report)"
      ],
      "metadata": {
        "id": "8Ybnbkxige-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"The movie was great and I really enjoyed the performances of the actors.\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"The movie was great and I really enjoyed the performances of the actors.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2kIdAj9hRgI",
        "outputId": "0126163e-9067-4aae-b722-34760267f9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie was great and I really enjoyed the performances of the actors.\n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"The movie was interesting and funny\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"The movie was so bad and I would not recommend it to anyone.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HILzwsdUhVun",
        "outputId": "6fe50992-d9c8-4fbd-90b9-f93916250c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie was so bad and I would not recommend it to anyone.\n",
            "Predicted sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"Worst movie of the year.\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"Worst movie of the year.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh2_bHPBhYDv",
        "outputId": "41b6d7d5-09a6-4981-e68b-49e786eaabfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worst movie of the year.\n",
            "Predicted sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68jLUuObXpx-"
      },
      "source": [
        "## Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kskc8UgFSFtA"
      },
      "outputs": [],
      "source": [
        "!pip install torchopenl3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5XDQ21_Ssl6"
      },
      "outputs": [],
      "source": [
        "!pip install openl3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbRgQQbWTUUz",
        "outputId": "7aa6b305-0b9e-4f74-b7ca-2bc8163df36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8lTmq3gTkuO",
        "outputId": "a0951fb3-b829-43fb-bbc4-81df41ccbf10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 11s 11s/step\n"
          ]
        }
      ],
      "source": [
        "import openl3\n",
        "import soundfile as sf\n",
        "\n",
        "audio, sr = sf.read('/content/drive/My Drive/Archive/pock_wash.mp3')\n",
        "emb, ts = openl3.get_audio_embedding(audio, sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9hZmn3EpWL3"
      },
      "outputs": [],
      "source": [
        "emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spXqi0-5Uj0v"
      },
      "outputs": [],
      "source": [
        "emb_f = torch.flatten(torch.tensor(emb))\n",
        "emb_f.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86h95ndvNyZv"
      },
      "source": [
        "Training our own audio model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4jjXaehtfPO",
        "outputId": "0b564fab-0ffd-4840-e90f-8c76e8b5f709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(128, 431)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
        "  wav,sr = librosa.load(file_path,sr=sr)\n",
        "  if wav.shape[0]<5*sr:\n",
        "    wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
        "  else:\n",
        "    wav=wav[:5*sr]\n",
        "  spec=librosa.feature.melspectrogram(y=wav, sr=sr, n_fft=n_fft,\n",
        "              hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
        "  spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
        "  return spec_db\n",
        "\n",
        "mels = get_melspectrogram_db('/content/drive/My Drive/Archive/pock_wash.mp3')\n",
        "mels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_IbDrwh2Trz",
        "outputId": "7e6a52ea-689a-426b-9f3d-204b85674008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(128, 431)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def spec_to_image(spec, eps=1e-6):\n",
        "  mean = spec.mean()\n",
        "  std = spec.std()\n",
        "  spec_norm = (spec - mean) / (std + eps)\n",
        "  spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
        "  spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
        "  spec_scaled = spec_scaled.astype(np.uint8)\n",
        "  return spec_scaled\n",
        "\n",
        "audio_img = spec_to_image(mels)\n",
        "audio_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUg8lfWGN1vt",
        "outputId": "32185593-dcee-4216-b6a1-5534cf41d5dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet34\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device('cuda:0')\n",
        "else:\n",
        "  device=torch.device('cpu')\n",
        "resnet_model = resnet34(pretrained=True)\n",
        "resnet_model.fc = nn.Linear(512,1)\n",
        "resnet_model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "resnet_model = resnet_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S21XjOm6VTsT",
        "outputId": "b073d352-6d13-4cb9-ee43-a55795c991f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:51<00:00, 38.47it/s]\n",
            "100%|██████████| 2000/2000 [00:52<00:00, 38.30it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "class ESC50Data(Dataset):\n",
        "  def __init__(self, base, df, in_col, out_col):\n",
        "    self.df = df\n",
        "    self.data = []\n",
        "    self.labels = []\n",
        "    self.c2i={}\n",
        "    self.i2c={}\n",
        "    self.categories = sorted(df[out_col].unique())\n",
        "    for i, category in enumerate(self.categories):\n",
        "      self.c2i[category]=i\n",
        "      self.i2c[i]=category\n",
        "    for ind in tqdm(range(len(df))):\n",
        "      row = df.iloc[ind]\n",
        "      file_path = os.path.join(base,row[in_col])\n",
        "      self.data.append(spec_to_image(get_melspectrogram_db(file_path))[np.newaxis,...])\n",
        "      self.labels.append(self.c2i[row['category']])\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.labels[idx]\n",
        "\n",
        "train = pd.read_csv('/content/drive/My Drive/ESC-50-master/meta/esc50.csv')\n",
        "train_data = ESC50Data('/content/drive/My Drive/ESC-50-master/audio', train, 'filename', 'category')\n",
        "valid_data = ESC50Data('/content/drive/My Drive/ESC-50-master/audio', train, 'filename', 'category')\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics of a Model"
      ],
      "metadata": {
        "id": "cH_6lOqFCnAa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8J0RG1lRbbBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet()\n",
        "optimizer = optim.Adam(model.parameters(),lr=2e-4)\n",
        "epochs = 10\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, loss_function, training_set, epochs, optimizer):\n",
        "  for e in epoch:\n",
        "    model.train():\n",
        "    batch_loss = []\n",
        "    for data in training_set:\n",
        "      x,y = data\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(x)\n",
        "      loss = loss_function(y_pred,y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      batch_loss.append(loss.item())\n",
        "      print(f'Accuracy' np.mean(y==y_pred))\n",
        "    print(f'Epoch - {e} Train-Loss : {np.mean(batch_loss)}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rsITl-7ZBVIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ilVzsKxfN-6c"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-4\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate)\n",
        "epochs = 50\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "resnet_train_losses=[]\n",
        "resnet_valid_losses=[]\n",
        "def lr_decay(optimizer, epoch):\n",
        "  if epoch%10==0:\n",
        "    new_lr = learning_rate / (10**(epoch//10))\n",
        "    optimizer = setlr(optimizer, new_lr)\n",
        "    print(f'Changed learning rate to {new_lr}')\n",
        "  return optimizer\n",
        "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, change_lr=None):\n",
        "  for epoch in tqdm(range(1,epochs+1)):\n",
        "    model.train()\n",
        "    batch_losses=[]\n",
        "    if change_lr:\n",
        "      optimizer = change_lr(optimizer, epoch)\n",
        "    for i, data in enumerate(train_loader):\n",
        "      x, y = data\n",
        "      optimizer.zero_grad()\n",
        "      x = x.to(device, dtype=torch.float32)\n",
        "      y = y.to(device, dtype=torch.long)\n",
        "      y_hat = model(x)\n",
        "      loss = loss_fn(y_hat, y)\n",
        "      loss.backward()\n",
        "      batch_losses.append(loss.item())\n",
        "      optimizer.step()\n",
        "    train_losses.append(batch_losses)\n",
        "    print(f'Epoch - {epoch} Train-Loss : {np.mean(train_losses[-1])}')\n",
        "    model.eval()\n",
        "    batch_losses=[]\n",
        "    trace_y = []\n",
        "    trace_yhat = []\n",
        "    for i, data in enumerate(valid_loader):\n",
        "      x, y = data\n",
        "      x = x.to(device, dtype=torch.float32)\n",
        "      y = y.to(device, dtype=torch.long)\n",
        "      y_hat = model(x)\n",
        "      loss = loss_fn(y_hat, y)\n",
        "      trace_y.append(y.cpu().detach().numpy())\n",
        "      trace_yhat.append(y_hat.cpu().detach().numpy())\n",
        "      batch_losses.append(loss.item())\n",
        "    valid_losses.append(batch_losses)\n",
        "    trace_y = np.concatenate(trace_y)\n",
        "    trace_yhat = np.concatenate(trace_yhat)\n",
        "    accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
        "    print(f'Epoch - {epoch} Valid-Loss : {np.mean(valid_losses[-1])} Valid-Accuracy : {accuracy}')\n",
        "train(resnet_model, loss_fn, train_loader, valid_loader, epochs, optimizer, resnet_train_losses, resnet_valid_losses, lr_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inK5njZvq7CQ"
      },
      "source": [
        "## Concotanate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clF0wnVDqgxC",
        "outputId": "55de7b97-ee27-4b1d-e630-12b4c6a2a5a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([154112])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "z = torch.cat((x,y,emb_f))\n",
        "z.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AiNMQnJenzZf",
        "Yed6FgyXpWiC",
        "68jLUuObXpx-",
        "inK5njZvq7CQ"
      ],
      "authorship_tag": "ABX9TyMGi5gZDXNkyvONhQe4xyIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}